## Autor

* **Nome:** Guilherme Hepp da Fonseca
* **Matr√≠cula:** 22202588
* **Email:** ghfonseca@inf.ufpel.edu.br

# Simula√ß√£o Distribu√≠da de Agentes (MPI + OpenMP) üöÄ

Este projeto √© uma simula√ß√£o h√≠brida e distribu√≠da desenvolvida como trabalho final para a disciplina de **Introdu√ß√£o ao Processamento Paralelo e Distribu√≠do**. O sistema modela um ecossistema com agentes aut√¥nomos disputando recursos naturais em um grid espacial massivo, utilizando arquiteturas de mem√≥ria distribu√≠da (MPI) e mem√≥ria compartilhada (OpenMP).

## Arquitetura H√≠brida

A simula√ß√£o foi projetada para extrair o m√°ximo de desempenho do hardware atrav√©s de dois n√≠veis de paralelismo:

1. **Paralelismo Inter-n√≥ (MPI):** O territ√≥rio global (grid) √© particionado horizontalmente. Cada processo do MPI gerencia um subgrid independente, comunicando-se com seus vizinhos exclusivamente para a troca de fronteiras (Ghost Cells / Halos) e migra√ß√£o de agentes utilizando `MPI_Sendrecv`.
2. **Paralelismo Intra-n√≥ (OpenMP):** Dentro de cada subgrid, o processamento da l√≥gica de decis√£o dos agentes e o consumo de recursos √© distribu√≠do entre m√∫ltiplas *threads*. Utilizamos diretivas como `#pragma omp parallel for schedule(dynamic)` para garantir o balanceamento din√¢mico de carga.

## Tecnologias Utilizadas

* **C (GCC)**
* **OpenMPI** (Message Passing Interface)
* **OpenMP** (Open Multi-Processing)

## ‚öôÔ∏è Pr√©-requisitos e Instala√ß√£o

Para compilar e executar este projeto em ambientes Linux (Ubuntu/Debian) ou WSL, certifique-se de ter o compilador C e as bibliotecas do OpenMPI instaladas:

```bash
sudo apt update
sudo apt install build-essential libopenmpi-dev openmpi-bin
```

## Como Compilar e Executar

### Compila√ß√£o
Utilize o compilador wrapper do MPI habilitando a flag do OpenMP:

```bash
mpicc -fopenmp simulacao.c -o simulacao
```

### Execu√ß√£o
A execu√ß√£o exige a defini√ß√£o do n√∫mero de threads (vari√°vel de ambiente do OpenMP) e o n√∫mero de processos distribu√≠dos (MPI). Exemplo com 4 threads e 4 processos:

```bash
OMP_NUM_THREADS=4 mpirun -np 4 ./simulacao
```

## An√°lise de Desempenho e Escalabilidade

Durante o desenvolvimento, a simula√ß√£o foi submetida a rigorosos testes de carga e desempenho (Grid de 2000x2000 = 4 milh√µes de c√©lulas, com 1000 ciclos de tempo):

* **Speedup e Tempo de Execu√ß√£o:** Em um teste variando de uma execu√ß√£o puramente sequencial (1 processo, 1 thread) para uma execu√ß√£o altamente paralela (4 processos, 4 threads), o tempo de execu√ß√£o real caiu de ~50.9 segundos para ~17.5 segundos, resultando em um Speedup de ~2.9x.
* **Toler√¢ncia a Cargas Massivas:** O sistema operou com sucesso sob estresse de 20.000 agentes migrando simultaneamente entre as fronteiras dos processos distribu√≠dos, sem apresentar vazamentos de mem√≥ria (Memory Leaks) ou falhas de segmenta√ß√£o (Segfaults). A sincroniza√ß√£o de m√©tricas globais via `MPI_Allreduce` manteve-se matematicamente precisa.
* **Resili√™ncia de Borda:** A rotina de migra√ß√£o dinamicamente alocada lidou corretamente com comportamentos de manada em dire√ß√£o aos limites nulos (`MPI_PROC_NULL`) do grid global.

---

